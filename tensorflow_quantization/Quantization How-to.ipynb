{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.TensorFlow用のQuantizationツールをインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install intel-quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.量子化するモデルをダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/intel-optimized-tensorflow/models/resnet50_fp32_pretrained_model.pb api/models/resnet50/resnet50_fp32_pretrained_model.pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.推論スクリプトのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/hiouchiy/IntelAI/master/tensorflow_quantization/infer_script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推論スクリプト（infer_script.py）について。\n",
    "\n",
    "IntelAIのGithubレポジトリには、いわゆる公式ベンチマークツールがあるのですが、今回はあえてそちらを使わずに（というかより実践的な状況を想定して）独自の推論スクリプトを用意しました。公式ツールよりも実装が緩いため、若干性能は劣りますが現実感を重要視しておりますので何卒ご容赦ください。\n",
    "\n",
    "スクリプトパラメータの説明\n",
    "- --input_graph・・・モデルファイルのパス\n",
    "- --dataset_dir・・・画像データフォルダのパス\n",
    "- --num_images・・・推論する画像枚数（この枚数を上記画像フォルダからランダムに選んで推論します。）\n",
    "- --openvino・・・OpenVINOの推論エンジン上で推論する場合はこちらにTrueをセット下さい。当然ながらモデルファイルはIRをして下さい。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.FP32モデルの性能確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、推論スクリプトの実行確認を兼ねて、量子化前のFP32のモデルの性能を確認してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!numactl -l python3 infer_script.py --input_graph \"api/models/resnet50/resnet50_fp32_pretrained_model.pb\" --dataset_dir /imagenet/images --num_images 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.モデルの入力Op、および、出力Opの名称を確認\n",
    "量子化を行うためには、モデルの入力および出力のOps名が必要です。つまり、どのOpsからどのOpsまでを量子化対象とするのか、決める必要があるからです。ユーティリティツールとして\"api/tools/summarize_graph.py\"が用意されていますので、下記のようにご使用下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 api/tools/summarize_graph.py --in_graph=api/models/resnet50/resnet50_fp32_pretrained_model.pb --input_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.量子化実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "量子化を実行する方法はいくつかあるのですが、ここでは恐らく最も汎用的な\"api/examples/quantize_cmd.py\"を使った方法をご紹介します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python api/examples/quantize_cmd.py --input_graph api/models/resnet50/resnet50_fp32_pretrained_model.pb --output_graph  api/models/resnet50/resnet50_int8_pretrained_model.pb --callback \"python3 ./infer_tf.py --input_graph {} --dataset_dir /imagenet/images --num_images 1000\" --inputs 'input' --outputs 'predict' --per_channel False --excluded_ops '' --excluded_nodes ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行中に各パラメータの意味を確認しましょう。\n",
    "\n",
    "- --input_graph api/models/resnet50/resnet50_fp32_pretrained_model.pb・・・元のFP32のモデルファイルのパス\n",
    "- --output_graph  api/models/resnet50/resnet50_int8_pretrained_model.pb・・・量子化後のINT8のモデルファイルの出力先\n",
    "- --callback \"python3 ./infer_tf.py --input_graph {} --dataset_dir /imagenet/images --num_images 1000\"・・・これが一番重要かつややこしい。量子化処理中にラフに量子化したモデルを一度推論して、FP32で表現されている各数値の使用されているダイナミックレンジをのMinとMaxを求める処理が実施されます。そのための推論スクリプトを実行するためのコマンドを指定します。この際、このスクリプトに入力するモデルファイルのパスはPlaceholderとして{}で指定します。そうすることで、処理中に一時ファイル（ラフな量子化モデル）のパスが動的に代入されます。また、ここでは推論画像枚数としてImagenetのValidation用画像50000枚から1000枚をランダムに使用すようにしていますが、Imagenet以外の画像データを使用する場合や枚数を変えたい場合は適宜変更ください。\n",
    "- --inputs 'input'・・・元のモデルの入力Opの名称\n",
    "- --outputs 'predict'・・・元のモデルの出力Opの名称\n",
    "- --per_channel False・・・\n",
    "- --excluded_ops ''・・・量子化の対象外とするOps一覧\n",
    "- --excluded_nodes ''・・・量子化対象外とするNode一覧\n",
    "\n",
    "おまけとして、[Intel Model Zoo](https://github.com/IntelAI/models)のモデルを使用する場合の方法もご紹介します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 api/examples/quantize_model_zoo.py --model resnet50 --in_graph /root/quantization/api/models/resnet50/resnet50_fp32_pretrained_model.pb --out_graph /root/quantization/api/models/resnet50/resnet50_int8_pretrained_model.pb --data_location /imagenet/tfrecord --models_zoo_location /root/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.量子化後のTensorFlowモデルを実行して性能比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは、量子化後のTensorFlowモデルを実行します。先ほどと同じ推論スクリプトを使用します。\n",
    "\n",
    "Intel TensorFlowをご使用いただいていれば、アプリケーションコードを変更しなくても、INT8のモデルを自動検知し、適切なCPU命令セット（Intel VNNI等）を実行します。推論処理のスピードがどの程度向上したかをご確認下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!numactl -l python3 infer_script.py --input_graph \"api/models/resnet50/resnet50_int8_pretrained_model.pb\" --dataset_dir /imagenet/images  --num_images 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlowでの作業は以上となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.OpenVINOのIRに変換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここからはIntel® OpenVINO™ Toolkitを用いた量子化方法をご紹介します。\n",
    "\n",
    "といってもまずは、元のTensorFlowのモデル（FP32）をOpenVINOのIR（Intermidiate Repretation）形式に変換するところから実施しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo.py --input_model=./api/models/resnet50/resnet50_fp32_pretrained_model.pb --input_shape=[1,224,224,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "念のため、IR(xml+bin)が生成されていることを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更に、IRをOpenVINOの推論エンジン（IE）上で実行してみます。TensorFlowの時と同じ推論スクリプトを使用します。モデルはFP32のままですが、IRに変換することでモデルの内部構造がCPUに最適化され、大きく性能が向上したことが確認できるかと思います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!numactl -l python3 infer_script.py --input_graph \"resnet50_fp32_pretrained_model.xml\" --dataset_dir /imagenet/images --num_images 50 --openvino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.IRの量子化実行\n",
    "IRの量子化はOpenVINOのPOT（Post-Training Optimization Toolkit）を使用して行います。事前にPOTの[セットアップ](https://docs.openvinotoolkit.org/latest/_README.html#install_post_training_optimization_toolkit)を完了させて下さい。\n",
    "\n",
    "その後、量子化のための各種設定を記述したConfigファイル（JSON）を準備（ダウンロード）します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/hiouchiy/IntelAI/master/tensorflow_quantization/resnet50_int8.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に今回使用するConfigファイルの中身を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat resnet50_int8.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "続いて、POTを使って量子化を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pot -c resnet50_int8.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実行が成功すると、resultsというフォルダが作成されます。そして、量子化済みのIRがその中に格納されています。\n",
    "\n",
    "results/se_resnet50_DefaultQuantization/日付日時のフォルダ/optimized/**.xml\n",
    "\n",
    "ちなみに、POTコマンドではなく、[Pythonスクリプト](https://docs.openvinotoolkit.org/latest/_sample_README.html#how_to_run_the_sample)を書いて同様のことを実現可能することも可能です。より細かなカスタマイズを行いたい時などはぜひご利用ください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.量子化後のIRを実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!numactl -l python3 infer_script.py --input_graph \"results/se_resnet50_DefaultQuantization/2020-06-07_11-15-38/optimized/se_resnet50.xml\" --dataset_dir /imagenet/images --num_images 50 --openvino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "おまけ。AccuracyChekerを使用したモデルの精度の確認方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pot -c resnet50_int8.json -e -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.それぞれの結果をグラフ化して比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "w = 0.4\n",
    "\n",
    "Y1 = [tf_total_time - tf_infer_time, cpu_total_time - cpu_infer_time]\n",
    "Y2 = [tf_infer_time, cpu_infer_time]\n",
    "\n",
    "X = np.arange(len(Y1))\n",
    "\n",
    "plt.bar(X, Y1, color='gray', width=w, label='Pre/Post', align=\"center\")\n",
    "plt.bar(X, Y2, color='blue', width=w, bottom=Y1, label='Inference', align=\"center\")\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title('Custom Visoin Model Performance Comparison')\n",
    "plt.ylabel(\"Spent time per one image (msec)\")\n",
    "\n",
    "plt.xticks(X, ['TensorFlow(CPU)','OpenVINO(CPU)'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちなみに公式ベンチマークツールでの測定方法はこちら↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!numactl -l python3 /opt/intel/openvino/deployment_tools/tools/benchmark_tool/benchmark_app.py -m resnet50_fp32_pretrained_model.xml -i ILSVRC2012_val_00000001.JPEG -niter 100 -b 1 -nireq 1 -nstreams 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /opt/intel/openvino/deployment_tools/tools/post_training_optimization_toolkit/configs/examples/quantization/classification/se_resnet50_pytorch_int8.json ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!numactl -N 0 -m 0 python3 /opt/intel/openvino/deployment_tools/tools/benchmark_tool/benchmark_app.py -m results/se_resnet50_DefaultQuantization/2020-06-07_06-52-09/optimized/se_resnet50.xml -i ILSVRC2012_val_00000001.JPEG -niter 100 -b 1 -nireq 1 -nstreams 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo.py --input_model=model.pb --input_shape=[1,224,224,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!numactl -N 0 -m 0 python3 /opt/intel/openvino/deployment_tools/tools/benchmark_tool/benchmark_app.py -m model.xml -i ILSVRC2012_val_00000001.JPEG -niter 100 -b 1 -nireq 1 -nstreams 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pot -c se_azure_cv_int8.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!numactl -N 0 -m 0 python3 /opt/intel/openvino/deployment_tools/tools/benchmark_tool/benchmark_app.py -m results/se_resnet50_DefaultQuantization/2020-06-07_07-25-25/optimized/se_resnet50.xml -i ILSVRC2012_val_00000001.JPEG -niter 100 -b 1 -nireq 1 -nstreams 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time #ここ追加\n",
    "\n",
    "def convert_to_opencv(image):\n",
    "    # RGB -> BGR conversion is performed as well.\n",
    "    image = image.convert('RGB')\n",
    "    r,g,b = np.array(image).T\n",
    "    opencv_image = np.array([b,g,r]).transpose()\n",
    "    return opencv_image\n",
    "\n",
    "def crop_center(img,cropx,cropy):\n",
    "    h, w = img.shape[:2]\n",
    "    startx = w//2-(cropx//2)\n",
    "    starty = h//2-(cropy//2)\n",
    "    return img[starty:starty+cropy, startx:startx+cropx]\n",
    "\n",
    "def resize_down_to_1600_max_dim(image):\n",
    "    h, w = image.shape[:2]\n",
    "    if (h < 1600 and w < 1600):\n",
    "        return image\n",
    "\n",
    "    new_size = (1600 * w // h, 1600) if (h > w) else (1600, 1600 * h // w)\n",
    "    return cv2.resize(image, new_size, interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "def resize_to_256_square(image):\n",
    "    h, w = image.shape[:2]\n",
    "    return cv2.resize(image, (256, 256), interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "def update_orientation(image):\n",
    "    exif_orientation_tag = 0x0112\n",
    "    if hasattr(image, '_getexif'):\n",
    "        exif = image._getexif()\n",
    "        if (exif != None and exif_orientation_tag in exif):\n",
    "            orientation = exif.get(exif_orientation_tag, 1)\n",
    "            # orientation is 1 based, shift to zero based and flip/transpose based on 0-based values\n",
    "            orientation -= 1\n",
    "            if orientation >= 4:\n",
    "                image = image.transpose(Image.TRANSPOSE)\n",
    "            if orientation == 2 or orientation == 3 or orientation == 6 or orientation == 7:\n",
    "                image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "            if orientation == 1 or orientation == 2 or orientation == 5 or orientation == 6:\n",
    "                image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    return image\n",
    "\n",
    "def run_normal(imageFile):\n",
    "    start1 = time.time() #ここ追加\n",
    "    \n",
    "    graph_def = tf.compat.v1.GraphDef()\n",
    "    labels = []\n",
    "\n",
    "    # These are set to the default names from exported models, update as needed.\n",
    "    filename = \"api/models/resnet50/resnet50_fp32_pretrained_model.pb\"\n",
    "    labels_filename = \"labels.txt\"\n",
    "\n",
    "    # Import the TF graph\n",
    "    with tf.io.gfile.GFile(filename, 'rb') as f:\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "    # Create a list of labels.\n",
    "#    with open(labels_filename, 'rt') as lf:\n",
    "#        for l in lf:\n",
    "#            labels.append(l.strip())\n",
    "\n",
    "    # Load from a file\n",
    "    image = Image.open(imageFile)\n",
    "\n",
    "    # Update orientation based on EXIF tags, if the file has orientation info.\n",
    "    image = update_orientation(image)\n",
    "\n",
    "    # Convert to OpenCV format\n",
    "    image = convert_to_opencv(image)\n",
    "\n",
    "    # If the image has either w or h greater than 1600 we resize it down respecting\n",
    "    # aspect ratio such that the largest dimension is 1600\n",
    "    image = resize_down_to_1600_max_dim(image)\n",
    "\n",
    "    # We next get the largest center square\n",
    "    h, w = image.shape[:2]\n",
    "    min_dim = min(w,h)\n",
    "    max_square_image = crop_center(image, min_dim, min_dim)\n",
    "\n",
    "    # Resize that square down to 256x256\n",
    "    augmented_image = resize_to_256_square(max_square_image)\n",
    "\n",
    "    # Get the input size of the model\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        input_tensor_shape = sess.graph.get_tensor_by_name('Placeholder:0').shape.as_list()\n",
    "    network_input_size = input_tensor_shape[1]\n",
    "\n",
    "    # Crop the center for the specified network_input_Size\n",
    "    augmented_image = crop_center(augmented_image, network_input_size, network_input_size)\n",
    "\n",
    "    # These names are part of the model and cannot be changed.\n",
    "    output_layer = 'predict:0'\n",
    "    input_node = 'input:0'\n",
    "\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        try:\n",
    "            prob_tensor = sess.graph.get_tensor_by_name(output_layer)\n",
    "            start2 = time.time() #ここ追加\n",
    "            predictions,  = sess.run(prob_tensor, {input_node: [augmented_image] })\n",
    "            infer_time = time.time() - start2\n",
    "        except KeyError:\n",
    "            print (\"Couldn't find classification output layer: \" + output_layer + \".\")\n",
    "            print (\"Verify this a model exported from an Object Detection project.\")\n",
    "            exit(-1)\n",
    "\n",
    "        # Print the highest probability label\n",
    "        highest_probability_index = np.argmax(predictions)\n",
    "        total_time = time.time() - start1\n",
    "        #print(imageFile + ',', 'Total Time: ' + str(int(total_time*1000.0)) + 'msec,', 'Infer Time: ' + str(int(infer_time*1000.0)) + 'msec,', 'Pred Label: ' + labels[highest_probability_index]) #ここ追加\n",
    "        print(imageFile + ',', 'Total Time: ' + str(int(total_time*1000.0)) + 'msec,', 'Infer Time: ' + str(int(infer_time*1000.0)) + 'msec,') #ここ追加\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#テスト用の画像をランダムに選択して推論実行\n",
    "import glob\n",
    "import random\n",
    "\n",
    "#file_list = glob.glob(\"test/*/*\")\n",
    "#img_path = random.choice(file_list)\n",
    "img_path = \"ILSVRC2012_val_00000001.JPEG\"\n",
    "run_normal(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここから"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time #ここ追加\n",
    "\n",
    "class Model(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.labels = []\n",
    "        labels_filename = \"labels.txt\"\n",
    "\n",
    "        # Create a list of labels.\n",
    "#        with open(labels_filename, 'rt') as lf:\n",
    "#            for l in lf:\n",
    "#                self.labels.append(l.strip())\n",
    "\n",
    "    def predict(self, imageFile):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def convert_to_opencv(self, image):\n",
    "        # RGB -> BGR conversion is performed as well.\n",
    "        image = image.convert('RGB')\n",
    "        r,g,b = np.array(image).T\n",
    "        opencv_image = np.array([b,g,r]).transpose()\n",
    "        return opencv_image\n",
    "\n",
    "    def crop_center(self, img,cropx,cropy):\n",
    "        h, w = img.shape[:2]\n",
    "        startx = w//2-(cropx//2)\n",
    "        starty = h//2-(cropy//2)\n",
    "        return img[starty:starty+cropy, startx:startx+cropx]\n",
    "\n",
    "    def resize_down_to_1600_max_dim(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        if (h < 1600 and w < 1600):\n",
    "            return image\n",
    "\n",
    "        new_size = (1600 * w // h, 1600) if (h > w) else (1600, 1600 * h // w)\n",
    "        return cv2.resize(image, new_size, interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    def resize_to_256_square(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        return cv2.resize(image, (256, 256), interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    def update_orientation(self, image):\n",
    "        exif_orientation_tag = 0x0112\n",
    "        if hasattr(image, '_getexif'):\n",
    "            exif = image._getexif()\n",
    "            if (exif != None and exif_orientation_tag in exif):\n",
    "                orientation = exif.get(exif_orientation_tag, 1)\n",
    "                # orientation is 1 based, shift to zero based and flip/transpose based on 0-based values\n",
    "                orientation -= 1\n",
    "                if orientation >= 4:\n",
    "                    image = image.transpose(Image.TRANSPOSE)\n",
    "                if orientation == 2 or orientation == 3 or orientation == 6 or orientation == 7:\n",
    "                    image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "                if orientation == 1 or orientation == 2 or orientation == 5 or orientation == 6:\n",
    "                    image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time #ここ追加\n",
    "\n",
    "class TFModel(Model):\n",
    "\n",
    "    def __init__(self, modelFilePath):\n",
    "        super(TFModel, self).__init__()\n",
    "        \n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "\n",
    "        # These are set to the default names from exported models, update as needed.\n",
    "        #filename = \"api/models/resnet50/resnet50_fp32_pretrained_model.pb\"\n",
    "        filename = modelFilePath\n",
    "\n",
    "        # Import the TF graph\n",
    "        with tf.io.gfile.GFile(filename, 'rb') as f:\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "        self.sess = tf.compat.v1.Session()\n",
    "                \n",
    "    def predict(self, imageFile):\n",
    "        start1 = time.time() #ここ追加\n",
    "\n",
    "        # Load from a file\n",
    "        image = Image.open(imageFile)\n",
    "\n",
    "        # Update orientation based on EXIF tags, if the file has orientation info.\n",
    "        image = super().update_orientation(image)\n",
    "\n",
    "        # Convert to OpenCV format\n",
    "        image = super().convert_to_opencv(image)\n",
    "\n",
    "        # If the image has either w or h greater than 1600 we resize it down respecting\n",
    "        # aspect ratio such that the largest dimension is 1600\n",
    "        image = super().resize_down_to_1600_max_dim(image)\n",
    "\n",
    "        # We next get the largest center square\n",
    "        h, w = image.shape[:2]\n",
    "        min_dim = min(w,h)\n",
    "        max_square_image = super().crop_center(image, min_dim, min_dim)\n",
    "\n",
    "        # Resize that square down to 256x256\n",
    "        augmented_image = super().resize_to_256_square(max_square_image)\n",
    "\n",
    "        # Get the input size of the model\n",
    "        input_tensor_shape = self.sess.graph.get_tensor_by_name('input:0').shape.as_list()\n",
    "        network_input_size = input_tensor_shape[1]\n",
    "\n",
    "        # Crop the center for the specified network_input_Size\n",
    "        augmented_image = super().crop_center(augmented_image, network_input_size, network_input_size)\n",
    "        frame = augmented_image\n",
    "\n",
    "        # These names are part of the model and cannot be changed.\n",
    "        output_layer = 'predict:0'\n",
    "        input_node = 'input:0'\n",
    "\n",
    "        try:\n",
    "            prob_tensor = self.sess.graph.get_tensor_by_name(output_layer)\n",
    "            start2 = time.time() #ここ追加\n",
    "            predictions, = self.sess.run(prob_tensor, {input_node: [augmented_image] })\n",
    "            infer_time = time.time() - start2\n",
    "        except KeyError:\n",
    "            print (\"Couldn't find classification output layer: \" + output_layer + \".\")\n",
    "            print (\"Verify this a model exported from an Object Detection project.\")\n",
    "            exit(-1)\n",
    "\n",
    "        # Print the highest probability label\n",
    "        highest_probability_index = np.argmax(predictions)\n",
    "        total_time = time.time() - start1\n",
    "        \n",
    "        #return total_time, infer_time, self.labels[highest_probability_index], frame  #ここ追加\n",
    "        return total_time, infer_time, \"\", frame  #ここ追加\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import io\n",
    "import IPython.display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def run_inference(model_type, target_device='CPU', total=500):\n",
    "    if model_type == 'tf':\n",
    "        model = TFModel(\"api/models/resnet50/resnet50_fp32_pretrained_model.pb\")\n",
    "    elif model_type == 'tf_int8':\n",
    "        model = TFModel(\"api/models/resnet50/resnet50_int8_pretrained_model.pb\")\n",
    "    else:\n",
    "        if target_device == 'GPU':\n",
    "            model = OpenVINOModel('GPU')\n",
    "        elif target_device == 'MYRIAD':\n",
    "            model = OpenVINOModel('MYRIAD')\n",
    "        else:\n",
    "            model = OpenVINOModel('CPU')\n",
    "\n",
    "    total_infer_spent_time = 0\n",
    "    total_spent_time = 0\n",
    "    list_df = pd.DataFrame( columns=['正解ラベル','予測ラベル','全処理時間(msec)','推論時間(msec)'] )\n",
    "\n",
    "    for i in range(total):\n",
    "        #file_list = glob.glob(\"dataset/*\")\n",
    "        #img_path = random.choice(file_list)\n",
    "        img_path = \"ILSVRC2012_val_00000001.JPEG\"\n",
    "        img_cat = os.path.split(os.path.dirname(img_path))[1]\n",
    "        total_time, infer_time, pred_label, frame = model.predict(img_path)\n",
    "\n",
    "        total_infer_spent_time += infer_time\n",
    "        total_spent_time += total_time\n",
    "\n",
    "        #print(img_path, str(int(total_time*1000.0)) + 'msec', str(int(infer_time*1000.0)) + 'msec', pred_label) #ここ追加\n",
    "        clear_output(wait=True)\n",
    "        cv2.putText(frame, str(i) + ':', (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,2550), 4)\n",
    "        cv2.putText(frame, str(i) + ':', (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "        cv2.putText(frame, str(img_cat), (10,80), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,2550), 4)\n",
    "        cv2.putText(frame, str(img_cat), (10,80), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "        cv2.putText(frame, str(pred_label), (10,130), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,2550), 4)\n",
    "        cv2.putText(frame, str(pred_label), (10,130), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2)\n",
    "\n",
    "        f = io.BytesIO()\n",
    "        PIL.Image.fromarray(frame).save(f, 'jpeg')\n",
    "        IPython.display.display(IPython.display.Image(data=f.getvalue()))\n",
    "\n",
    "        tmp_se = pd.Series( [img_cat, pred_label, str(int(total_time * 1000)), str(int(infer_time * 1000)) ], index=list_df.columns )\n",
    "        list_df = list_df.append( tmp_se, ignore_index=True ) \n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print()\n",
    "    print('全' + str(total) + '枚 完了！')\n",
    "    print()\n",
    "    print(\"平均処理時間: \" + str(int((total_spent_time / total)*1000.0)) + \" ms/枚\")\n",
    "    print(\"平均推論時間: \" + str(int((total_infer_spent_time / total)*1000.0)) + \" ms/枚\")\n",
    "    display(list_df)\n",
    "\n",
    "    return int((total_spent_time / total)*1000.0), int((total_infer_spent_time / total)*1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_total_time, tf_infer_time = run_inference('tf_int8', total=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 infer_tf.py --input_graph \"api/models/resnet50/resnet50_int8_pretrained_model.pb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
